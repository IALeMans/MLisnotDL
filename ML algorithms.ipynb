{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IALeMans/MLisnotDL/blob/master/ML%C2%A0algorithms.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "TVZa71QuLAfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Types of Machine Learning Algorithms"
      ]
    },
    {
      "metadata": {
        "id": "2mmb1vpwJq_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Supervised Algorithms"
      ]
    },
    {
      "metadata": {
        "id": "X8OjTVn-KIHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This algorithm consist of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data. Examples of Supervised Learning: Regression, Decision Tree, Random Forest, KNN, Logistic Regression etc."
      ]
    },
    {
      "metadata": {
        "id": "suzzXAFgKtrk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "IWXRCu0IJyL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Algorithms"
      ]
    },
    {
      "metadata": {
        "id": "qk2qAVlAKbej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this algorithm, we do not have any target or outcome variable to predict / estimate.  It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention. Examples of Unsupervised Learning: Apriori algorithm, K-means."
      ]
    },
    {
      "metadata": {
        "id": "fw0KpAadJ4Ke",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "IHrAxmkqKlUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using this algorithm, the machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions. Example of Reinforcement Learning: Markov Decision Process"
      ]
    },
    {
      "metadata": {
        "id": "09Tce0iaK5Rd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "r-TROS1MLN5t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Common Machine Learning Algorithms"
      ]
    },
    {
      "metadata": {
        "id": "5ieqNd45MWH_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1.   Linear Regression\n",
        "2.   Logistic Regression\n",
        "3.   Decision Tree\n",
        "4.   SVM (et kernel SVM)\n",
        "5.   Naive Bayes\n",
        "6.   kNN\n",
        "7.   K-Means\n",
        "8.   Random Forest\n",
        "9.   PCA\n",
        "10. Gradient Boosting algorithms\n",
        "        GBM\n",
        "        XGBoost\n",
        "        LightGBM\n",
        "        CatBoost\n"
      ]
    },
    {
      "metadata": {
        "id": "A9bUdeFhMYro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n"
      ]
    },
    {
      "metadata": {
        "id": "YgwfrjRtNNRn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![regression lineaire](https://user.oc-static.com/upload/2017/11/07/15100617101762_RegressionLineaireSimple1.jpeg) \n"
      ]
    },
    {
      "metadata": {
        "id": "bpXmy_WmNTFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression Logistic"
      ]
    },
    {
      "metadata": {
        "id": "XtDN0N2sNV4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://qph.fs.quoracdn.net/main-qimg-779caa51d21421d57326d87616be6525)"
      ]
    },
    {
      "metadata": {
        "id": "Oz0v111-N0zQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SVM - Kernel SVM"
      ]
    },
    {
      "metadata": {
        "id": "jG21FFvxOU2a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![SVM](https://www.hackerearth.com/blog/wp-content/uploads/2017/02/Margin.png)\n",
        "\n",
        "![kernel SVM](https://www.hackerearth.com/blog/wp-content/uploads/2017/02/kernel.png)"
      ]
    },
    {
      "metadata": {
        "id": "KOtBPN-RPSJq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "J-Gkdf_SR930",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://se.mathworks.com/help/examples/stats/win64/TrainANaiveBayesClassifierFitcnbExample_01.png)"
      ]
    },
    {
      "metadata": {
        "id": "K5rY27OJSHhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# kNN\n",
        "kernel nearest neighbors"
      ]
    },
    {
      "metadata": {
        "id": "fRQENtKUSQAd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://helloacm.com/wp-content/uploads/2016/03/2012-10-26-knn-concept.png)"
      ]
    },
    {
      "metadata": {
        "id": "hPrj15K9TmKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# k Means"
      ]
    },
    {
      "metadata": {
        "id": "FwYJyE95Uxli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://i.imgur.com/S65Sk9c.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "KNT-SJqHUPRP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://www.cs.umd.edu/~mount/Projects/KMeans/Images/centers.gif)"
      ]
    },
    {
      "metadata": {
        "id": "6TRWYvkOTq71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](http://2.bp.blogspot.com/-liUwQtQkkaY/VWTEEIJ_LdI/AAAAAAAAA8Y/3x3PJxIT2jY/s400/Clustering.png)"
      ]
    },
    {
      "metadata": {
        "id": "96vMDnUpU4vu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://i.imgur.com/k3o6NxK.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "-vmokIApNwax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "metadata": {
        "id": "8mQZArP_OMIk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://clearpredictions.com/Images/Decision_Tree_Example.png)"
      ]
    },
    {
      "metadata": {
        "id": "ssgBP0gPVRJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# random forest"
      ]
    },
    {
      "metadata": {
        "id": "j8MXOtXVVTpu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/1600/1*i0o8mjFfCn-uD79-F1Cqkw.png)"
      ]
    },
    {
      "metadata": {
        "id": "T-m2CRhvVdk5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyse en Compante Principale"
      ]
    },
    {
      "metadata": {
        "id": "oVwWCzMrViTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*H38t3YUv_QktLwalzDYRRg.png)"
      ]
    },
    {
      "metadata": {
        "id": "gTNUnevGWjkX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "metadata": {
        "id": "R7v4C3XOWmeC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. "
      ]
    }
  ]
}